"""
Functions to help calibration of Bruker spectra

includes both Sanjee's functions and ones written by Chris for single spectra case
"""
import os
from glob import glob
import pandas as pd
from math import floor
import math
from matplotlib import pyplot as plt
from cycler import cycler
import numpy as np
from scipy.fftpack import fft, ifft
from scipy.interpolate import interp1d
from scipy.optimize import curve_fit, minimize_scalar
from matplotlib.collections import LineCollection
from matplotlib.colors import ListedColormap, BoundaryNorm


class cd:
    """Context manager for changing the current working directory
    from https://stackoverflow.com/questions/431684/how-do-i-change
    -directory-cd-in-python/13197763#13197763
    """

    def __init__(self, newPath):
        self.newPath = os.path.expanduser(newPath)

    def __enter__(self):
        self.savedPath = os.getcwd()
        os.chdir(self.newPath)

    def __exit__(self, etype, value, traceback):
        os.chdir(self.savedPath)


def update_figure(series, size=(6, 3.6)):
    """Update figure parameters

    Args:
        series (int): Number of different coloured lines in plot
        size (list, optional): Figure size. Defaults to (10, 5.95).
    """
    params = {
        "axes.labelsize": 8,  # Set to size 8 to start with
        "font.size": 8,  # Set to size 8 to start with
        "font.family": "sans-serif",  # Not given initially - only optional
        "font.serif": "Arial",  # Not given initially - only optional
        "legend.fontsize": 8,  # Set to size 8 to start with
        "xtick.labelsize": 8,  # Set to size 8 to start with
        "ytick.labelsize": 8,  # Set to size 8 to start with
        "figure.figsize": size,  # Set to [6,4] to start with
        "axes.prop_cycle": cycler(color=plt.cm.plasma(np.linspace(0, 1, series))),
    }
    plt.rcParams.update(params)


def load_gui(filename):
    """Loads data from GUI logfile and returns a Pandas dataframe
    containing the data

    Args:
        filename (string): Filename of GUI logfile

    Returns:
        pandas dataframe: Pandas dataframe containing the data from the GUI
        dataframe has following columns:
            "date_string" Date of measurement  YYYYMMDD
            "time_string" Time of measurement  HH:MM:SS
            "PRT1"        Temp of PRT1         °C
            "PRT2"        Temp of PRT2         °C
            "PRT3"        Temp of PRT3         °C
            "PRT4"        Temp of PRT4         °C
            "PRT5"        Temp of PRT5         °C
            "PRT6"        Temp of PRT6         °C
            "HBB"         Temp of HBB          °C
            "CBB"         Temp of CBB          °C
            "time"        Time of measurement  Seconds since midnight
            "angle"       Angle of scan mirror °
                          270:HBB 225:CBB 180:zenith
    """
    names = [
        "date_string",
        "time_string",
        "PRT1",
        "PRT2",
        "PRT3",
        "PRT4",
        "PRT5",
        "PRT6",
        "HBB",
        "CBB",
        "time",
        "angle",
    ]
    gui_data = pd.read_csv(
        filename,
        header=0,
        names=names,
        usecols=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],
        na_values="-"
    )
    return gui_data


def string_to_seconds_bruker(time_string):
    """Return seconds since midnight from time string
    provided by the Bruker

    Args:
        time_string (string): string representing time
            format hh:mm:ss.ssss (length of h, m and s does not matter)
        n.b. secondt time is rounded DOWN to the nearest whole second

    Returns:
        float: seconds since midnight
    """
    seperate = time_string.split(":")
    time_seconds = (
        float(seperate[0]) * 60 * 60 +
        float(seperate[1]) * 60 + floor(float(seperate[2]))
    )
    return time_seconds


def load_ints(folder, len_int=0, centre_place=False):
    """Load interferograms and corresponding times
    from folder generated by EM27

    Args:
        folder (string): Name of folder where interferograms are stored

    Returns:
        array: array of all interferograms in folder
        array: array of timestamps of all interforagrams in folder
               in units of seconds since midnight
    """
    ints_names = glob(folder + "/*.0")
    ints_names.sort()
    centre_places = []
    for i, name in enumerate(ints_names):
        data = np.fromfile(name, np.float32)
        # print("Int: ", name)
        centre_point = np.argmax(data[10000:-10000])
        centre_places.append(centre_point)
        if i == 0:
            if len_int==0:
                ints = np.empty((len(ints_names), len(data)))
            else:
                ints = np.empty((len(ints_names), len_int))
        if len_int==0:
            ints[i, :] = data
        else:
            ints[i, :] = data[0:len_int]
    times_name = glob(folder + "/*ResultSeries.txt")[0]
    time_strings = np.loadtxt(
        times_name, dtype="str", delimiter="\t", skiprows=2, usecols=[1], unpack=True,
    )
    times = []
    for time in time_strings:
        times.append(string_to_seconds_bruker(time))
    if centre_place==True:
        return ints, times, centre_places
    else:
        return ints, times


def colocate_ints_angles(times, gui_data):
    """Find the angles of the mirror at given times

    Args:
        times (list-like): Times at which to find mirror angle
        gui_data (pandas dataframe): Pandas dataframe of gui log file
        created using load_gui

    Returns:
        list: list of angles at each time
    """
    angles = []
    for i in range(len(times)):
        gui_index = gui_data["time"].sub(times[i]).abs().idxmin()
        angle = gui_data.loc[gui_index, "angle"]
        angles.append(angle)
    return angles


def load_co2(filenames):
    """Load co2 log files produced by vaisala intrument
    At the moment assumes 12 hour clock

    Args:
        filenames (str or list): Filename or list of multiple filenames
        where the co2 data is stored. Repeated data is automatically removed

    Returns:
        array: Times of measurment in seconds since midnight
        array: Coresponding co2 measuremnts (ppm)
    """
    # Load data if loading single file
    if isinstance(filenames, str):
        if filenames.split(".")[-1] == "csv":
            date_strings, co2 = np.genfromtxt(
                filenames,
                dtype=None,
                skip_header=4,
                usecols=[0, 1],
                delimiter=",",
                unpack=True,
                comments="#",
                encoding="UTF-8",
            )
        else:
            date_strings, co2 = np.genfromtxt(
                filenames,
                dtype=None,
                skip_header=4,
                usecols=[0, 1],
                delimiter="\t",
                unpack=True,
                comments="#",
                encoding="UTF-8",
            )
        times = []
        for date_string in date_strings:
            time = string_to_seconds_vaisala(date_string)
            times.append(time)
        times = np.array(times)
        # missing_mask = np.where(co2 != "-")[0]
        # times = times[missing_mask]
        # co2 = co2[missing_mask]
        co2 = co2.astype(np.float)
    # Load data if list of files
    if isinstance(filenames, list):
        all_times, all_co2 = [], []
        for filename in filenames:
            time_temp, co2_temp = load_co2(filename)
            all_times.append(time_temp)
            all_co2.append(co2_temp)
        # Remove duplicate data
        times_flat = [item for sublist in all_times for item in sublist]
        co2_flat = [item for sublist in all_co2 for item in sublist]
        data = np.array((times_flat, co2_flat))
        data_unique = np.unique(data, axis=1)
        times = data_unique[0, :]
        co2 = data_unique[1, :]
    return times, co2


def load_pth(filenames):
    """Load data from vaisala pth logger

    Args:
        filenames (str or list): Filename or list of multiple filenames
        where the pth data is stored. Repeated data is automatically removed

    Returns:
        array: Times of measurement in seconds since midnight
        array: Coresponding pressure (hPa)
        array: Coresponding temperature (C)
        array: Coresponding humidity (%RH)
    """
    # Load data if loading single file
    if isinstance(filenames, str):
        if filenames.split(".")[-1] == "csv":
            date_strings, p, t, h = np.genfromtxt(
                filenames,
                dtype=str,
                skip_header=1,
                delimiter=",",
                unpack=True,
                encoding=None,
            )
        else:
            date_strings, p, t, h = np.genfromtxt(
                filenames,
                dtype=str,
                skip_header=1,
                delimiter="\t",
                unpack=True,
                comments="#",
                encoding=None,
            )
        times = []
        for date_string in date_strings:
            time = string_to_seconds_vaisala(date_string)
            times.append(time)
        times = np.array(times)
        p = p.astype(np.float64)
        t = t.astype(np.float64)
        h = h.astype(np.float64)
        # SLMs HAVE changed these to np.float64
    # Load data if list of files
    if isinstance(filenames, list):
        all_times, all_p, all_t, all_h = [], [], [], []
        for filename in filenames:
            time_temp, p_temp, t_temp, h_temp = load_pth(filename, csv=csv)
            all_times.append(time_temp)
            all_p.append(p_temp)
            all_t.append(t_temp)
            all_h.append(h_temp)
        # Remove duplicate data
        times_flat = [item for sublist in all_times for item in sublist]
        p_flat = [item for sublist in all_p for item in sublist]
        t_flat = [item for sublist in all_t for item in sublist]
        h_flat = [item for sublist in all_h for item in sublist]
        data = np.array((times_flat, p_flat, t_flat, h_flat))
        data_unique = np.unique(data, axis=1)
        times = data_unique[0, :]
        p = data_unique[1, :]
        t = data_unique[2, :]
        h = data_unique[3, :]
        print(len(times_flat), len(times))
    return times, p, t, h


def string_to_seconds_vaisala(string):
    """Convert datetime string from vaisala instument
    to seconds since midnight. At the moment using 12 hour
    clock

    Args:
        string (str): String containing date and time in the
        format 7/21/2021 12:10:50 PM

    Returns:
        float: seconds since midnight
    """
    string_split = string.split(" ")
    time_raw = string_to_seconds_bruker(string_split[1])
    time_split = string_split[1].split(":")
    if time_split[0] == "12":
        if string_split[2] == "AM":
            time_raw -= 43200
    elif string_split[2] == "PM":
        time_raw += 43200
    return time_raw


def average_ints(ints, times, angles, averaging_length):
    """Average interferograms in groups specified by
    averaging length. Returns averaged interferograms
    and start and end time for each average

    Args:
        ints (array): interferograms to be averaged in
                      shape(time, interferogram_length)
        times (array or list): time of each interferogram
        angles (array or list): angle for each interferogram
        averaging_length (int): number of interferograms to average

    Returns:
        array: averaged interferograms shape(time, interferogram_length)
        array: start and end times for each averaged interferogram
        array: angle for each averaged interferogam
    """
    ints = np.reshape(np.array(ints), (len(times), -1))
    times = np.array(times)
    angles = np.array(angles)
    # Reshape array to make averaging easier
    ints_reshaped = ints.reshape(-1, averaging_length, len(ints[0, :]))
    ints_mean = np.mean(ints_reshaped, axis=1)
    start_times = times[::averaging_length]
    end_times = times[averaging_length - 1:: averaging_length]
    times = np.transpose(np.array((start_times, end_times)))
    # Check that we are not averaging over differnt angles
    angles_reshaped = np.transpose(angles.reshape(-1, averaging_length))
    angles_average = np.mean(angles_reshaped, axis=0)
    angles_equal = np.all(angles_reshaped == angles_reshaped[0, :], axis=0)
    if not np.all(angles_equal):
        print("\n!!!! Warning !!!!\nAveraging over different angle values\n")
    return ints_mean, times, angles_average


def load_averaged_int(filename):
    """Load averaged interferogram produced using
    2_prepare_interferogram.py

    Args:
        filename (string): Loaction of interferogram file

    Returns:
        array: interferogram
        array: start and end times of interfergram
        float: mirror angle for interferogram
    """
    interferogram = np.loadtxt(filename)
    with open(filename, "r") as f:
        for i, line in enumerate(f):
            if i == 2:
                times_raw = line
            if i == 4:
                angle_raw = line
            if i > 4:
                break
    times_split = times_raw.split(" ")[1:]
    time = np.array((times_split[0], times_split[1][:-1]), dtype=np.float64)
    # SLM EDITTED the dtype to be np.float64
    angle = np.float64(angle_raw[2:-1])
    return interferogram, time, angle


def load_response_function(filename):
    """Load response function produced using
    2_prepare_interferogram.py

    Args:
        filename (string): Loaction of interferogram file

    Returns:
        array: wavenumber scale
        array: apodised response function
        array: unapodised response function
        dict:  other information
                including
                HBB_temp  Temperature of HBB (C)
                HBB_std   Standard deviation of HBB temp
                HBB_times Times for start and end of HBB views
                CBB_temp  Temperature of CBB (C)
                CBB_std   Standard deviation of CBB temp
                CBB_times Times for start and end of CBB views
                time      Midpoint time for response function calculation
    """
    wn, resp = np.loadtxt(filename, unpack=True,)
    # Remove first line of resp function as
    # outside of area of sensitivity and usually nan
    wn, resp = wn[1:], resp[1:]
    with open(filename, "r") as f:
        for i, line in enumerate(f):
            if i == 4:
                HBB_times_raw = line
            if i == 6:
                HBB_temp_raw = line
            if i == 10:
                CBB_times_raw = line
            if i == 12:
                CBB_temp_raw = line
            if i > 12:
                break
    HBB_times_split = HBB_times_raw.split(" ")[1:]
    HBB_times = np.array(
        (HBB_times_split[0], HBB_times_split[1][:-1]), dtype=np.float,)
    CBB_times_split = CBB_times_raw.split(" ")[1:]
    CBB_times = np.array(
        (CBB_times_split[0], CBB_times_split[1][:-1]), dtype=np.float,)
    HBB_temps_split = HBB_temp_raw.split("+/-")
    HBB_temp = float(HBB_temps_split[0].split(" ")[1])
    HBB_std = float(HBB_temps_split[-1][:-1])
    CBB_temps_split = CBB_temp_raw.split("+/-")
    CBB_temp = float(CBB_temps_split[0].split(" ")[1])
    CBB_std = float(CBB_temps_split[-1][:-1])
    time = (
        max(HBB_times[0], HBB_times[1], CBB_times[0], CBB_times[1])
        + min(HBB_times[0], HBB_times[1], CBB_times[0], CBB_times[1])
    ) / 2.0
    params = {
        "HBB_temp": HBB_temp,
        "HBB_std": HBB_std,
        "HBB_times": HBB_times,
        "CBB_temp": CBB_temp,
        "CBB_std": CBB_std,
        "CBB_times": CBB_times,
        "time": time,
    }
    return wn, resp, params


def load_spectrum_cycle(filename, info=True, info_only=False):
    """Load spectrum produced using
    4_calibrate_spectra_in_cycles.py

    Args:
        filename (string): Loaction of spectrum file

    Returns:
        array: wavenumber scale (cm-1)
        array: spectrum (W m-2 sr-1 (cm-1)-1)
        array: NESR (W m-2 sr-1 (cm-1)-1)
        array: +ve calibration error (W m-2 sr-1 (cm-1)-1)
        array: -ve calibration error (W m-2 sr-1 (cm-1)-1)
        if info:
            dict:  other information
                    including
                    HBB_temp    Temperature of HBB (C)
                    HBB_std     Standard deviation of HBB temp
                    HBB_times   Times for start and end of HBB view
                    CBB_temp    Temperature of CBB (C)
                    CBB_std     Standard deviation of CBB temp
                    CBB_times   Times for start and end of CBB view
                    scene_times Times for start and end of scene view
                    time        Midpoint time for scene view
    """
    if not info_only:
        wn, rad, NESR, plus_cal, minus_cal = np.loadtxt(filename, unpack=True,)
    if not info:
        return wn, rad, NESR, plus_cal, minus_cal
    with open(filename, "r") as f:
        for i, line in enumerate(f):
            if i == 4:
                scene_times_raw = line
            if i == 5:
                angle_raw = line
            if i == 9:
                HBB_times_raw = line
            if i == 11:
                HBB_temp_raw = line
            if i == 15:
                CBB_times_raw = line
            if i == 17:
                CBB_temp_raw = line
            if i > 17:
                break
    angle = float(angle_raw.split(" ")[-1][:-1])
    scene_times_split = scene_times_raw.split(" ")[1:]
    scene_times = np.array(
        (scene_times_split[0], scene_times_split[1][:-1]), dtype=np.float,
    )
    HBB_times_split = HBB_times_raw.split(" ")[1:]
    HBB_times = np.array(
        (HBB_times_split[0], HBB_times_split[1][:-1]), dtype=np.float,)
    HBB_times_split = HBB_times_raw.split(" ")[1:]
    HBB_times = np.array(
        (HBB_times_split[0], HBB_times_split[1][:-1]), dtype=np.float,)
    CBB_times_split = CBB_times_raw.split(" ")[1:]
    CBB_times = np.array(
        (CBB_times_split[0], CBB_times_split[1][:-1]), dtype=np.float,)
    HBB_temps_split = HBB_temp_raw.split("+/-")
    HBB_temp = float(HBB_temps_split[0].split(" ")[1])
    HBB_std = float(HBB_temps_split[-1][:-1])
    CBB_temps_split = CBB_temp_raw.split("+/-")
    CBB_temp = float(CBB_temps_split[0].split(" ")[1])
    CBB_std = float(CBB_temps_split[-1][:-1])
    time = (scene_times[0] + scene_times[1]) / 2.0
    params = {
        "angle": angle,
        "scene_times": scene_times,
        "HBB_temp": HBB_temp,
        "HBB_std": HBB_std,
        "HBB_times": HBB_times,
        "CBB_temp": CBB_temp,
        "CBB_std": CBB_std,
        "CBB_times": CBB_times,
        "time": time,
    }
    if info_only:
        return params
    return wn, rad, NESR, plus_cal, minus_cal, params


def load_emissivity(filename, info=True, info_only=False):
    """Loas emissivity calculated using 7_calculate_emissivity.py

    Args:
        filename (str): location of emissivity file
        info (bool, optional): If true load info and emissivity. Defaults to True.
        info_only (bool, optional): If true load info only. Defaults to False.

    Returns:
        if not info_only
        array: Wavenumber (cm-1)
        array: Emissivity
        if info
        dict: Information about emissivity calculation including:
            "scene_times": start and finish time of scene view
                (s since midnight)
            "time": average time of scene view
                (s since midnight)
            "scene_view": filename for scene spectrum
            "sky_view": filename for sky spectrum
            "atmos_temp": Temperature of the atmosphere (C)
            "atmos_std": Standard deviation in temperature of the
                atmosphere over the scene view (C)
            "surface_temp": Retrieved temperature of the surface
            "surface_std":Uncertainty in the retrieved
                temeprature of the surface (C)
            "surface_temp_guess": Inital guess of surface temperature
                from the average of PRT1 and PRT2 (C)
    """
    if not info_only:
        wn, emis = np.loadtxt(filename, unpack=True,)
    if not info:
        return wn, emis
    with open(filename, "r") as f:
        for i, line in enumerate(f):
            if i == 2:
                scene_view_raw = line
            if i == 3:
                sky_view_raw = line
            if i == 4:
                scene_times_raw = line
            if i == 5:
                atmos_temp_raw = line
            if i == 6:
                surface_temp_raw = line
            if i == 7:
                surface_guess_raw = line
            if i > 7:
                break
    scene_times_split = scene_times_raw.split(" ")
    scene_times = np.array(
        (scene_times_split[-2], scene_times_split[-1][:-1]), dtype=np.float,
    )
    time = (scene_times[0] + scene_times[1]) / 2.0
    scene_view = int(scene_view_raw.split(":")[-1])
    sky_view = int(sky_view_raw.split(":")[-1])
    atmos_temp = float(atmos_temp_raw.split(" ")[-3])
    atmos_std = float(atmos_temp_raw.split(" ")[-1])
    surface_temp = float(surface_temp_raw.split(" ")[-3])
    surface_std = float(surface_temp_raw.split(" ")[-1])
    surface_guess = float(surface_guess_raw.split(" ")[-1])
    params = {
        "scene_times": scene_times,
        "time": time,
        "scene_view": scene_view,
        "sky_view": sky_view,
        "atmos_temp": atmos_temp,
        "atmos_std": atmos_std,
        "surface_temp": surface_temp,
        "surface_std": surface_std,
        "surface_temp_guess": surface_guess,
    }
    if info_only:
        return params
    return wn, emis, params


def load_emissivity_error(filename, info=True, info_only=False):
    """Load emissivity error estimates

    Args:
        filename (str): location of emissivity error file
        info (bool, optional): If true load info and emissivity. Defaults to True.
        info_only (bool, optional): If true load info only. Defaults to False.

    Returns:
        if not info_only
        array: Wavenumber (cm-1)
        array: Emissivity error minus (error when parameter is decreased)
        array: Emissivity error plus (error when parameter is increased)
        if info
        dict: Information about emissivity calculation including:
            "scene_times": start and finish time of scene view
                (s since midnight)
            "time": average time of scene view
                (s since midnight)
            "scene_view": filename for scene spectrum
            "sky_view": filename for sky spectrum
            "atmos_temp": Temperature of the atmosphere (C)
            "atmos_std": Standard deviation in temperature of the
                atmosphere over the scene view (C)
            "surface_temp": Retrieved temperature of the surface
            "surface_std":Uncertainty in the retrieved
                temeprature of the surface (C)
            "surface_temp_guess": Inital guess of surface temperature
                from the average of PRT1 and PRT2 (C)
            "error_value": Value of error that produced the difference
            "error_name": Name of the error that produced the change
    """
    if not info_only:
        wn, emis_lower, emis_higher = np.loadtxt(filename, unpack=True,)
    if not info:
        return wn, emis_lower, emis_higher
    with open(filename, "r") as f:
        for i, line in enumerate(f):
            if i == 2:
                scene_view_raw = line
            if i == 3:
                sky_view_raw = line
            if i == 4:
                scene_times_raw = line
            if i == 5:
                atmos_temp_raw = line
            if i == 6:
                surface_temp_raw = line
            if i == 7:
                surface_guess_raw = line
            if i == 8:
                error_raw = line
            if i > 8:
                break
    scene_times_split = scene_times_raw.split(" ")
    scene_times = np.array(
        (scene_times_split[-2], scene_times_split[-1][:-1]), dtype=np.float,
    )
    time = (scene_times[0] + scene_times[1]) / 2.0
    scene_view = int(scene_view_raw.split(":")[-1])
    sky_view = int(sky_view_raw.split(":")[-1])
    atmos_temp = float(atmos_temp_raw.split(" ")[-3])
    atmos_std = float(atmos_temp_raw.split(" ")[-1])
    surface_temp = float(surface_temp_raw.split(" ")[-3])
    surface_std = float(surface_temp_raw.split(" ")[-1])
    surface_guess = float(surface_guess_raw.split(" ")[-1])
    error_split = error_raw.split("+/-")
    error_value = error_split[-1]
    error_name = error_split[0].split(":")[-1]
    params = {
        "scene_times": scene_times,
        "time": time,
        "scene_view": scene_view,
        "sky_view": sky_view,
        "atmos_temp": atmos_temp,
        "atmos_std": atmos_std,
        "surface_temp": surface_temp,
        "surface_std": surface_std,
        "surface_temp_guess": surface_guess,
        "error_value": error_value,
        "error_name": error_name
    }
    if info_only:
        return params
    return wn, emis_lower, emis_higher, params


def planck(wns, temp):
    """Calculate radiance for given wavenumbers and temperature

    Args:
        wns (array or float): wavenumbers at which to calculate
        radiance (cm-1)
        temp (float): black body tmeperature (C)

    Returns:
        array or float: Radiance at each wavenumber
        (W m^{-2} sr^{-1} cm^{-1})
    """
    h = 6.626e-34
    c = 3.0e8
    k = 1.381e-23
    temp = temp + 273.15

    planck_a = 2 * h * (c ** 2)
    planck_e = h * c / k
    radiance = (
        100
        * planck_a
        * ((wns * 100) ** 3)
        / (np.exp(planck_e * (wns * 100) / temp) - 1)
    )

    return radiance


def finesse_fft(interferogram, resolution, fre_interval, low_res_trunk=16384):
    """Perform FFT on FINESSE spectrum adapted from IDL code from Jon Murray

    Args:
        interferogram (array): interferogram to be FFT'd
        resolution (float): resolution of spectrum
        fre_interval (float): resolution of output grid
        low_res_trunk (int, optional): number of points to take
        when calculating phase angle. Defaults to 16384.

    Returns:
        array[4,length]: apodised spectrum apodised by OPD of 1.8cm
        columns are frequency (cm-1), real part of spectrum,
            imaginary part of spectrum, phase angle
        array[4,length]: full resolution spectrum columns same as above
    """
    HeNe = 6.32816e-5  # (Helium Neon laser wavelength in cm)
    # Calculate the optical path difference neccessary
    # for the required spectral resolution assuming boxcar apodisation
    OPD = 0.605 / resolution
    # samples covering the range 0-7901.19 cm-1
    # (Free spectral range based on 1st alias)
    padded_samples = round(1.0 / (HeNe * fre_interval))
    # Set the frequency scale applicable to the full
    # interferogram scan input
    full_fre = np.arange(padded_samples) / HeNe / padded_samples

    # Check for spurious values that can appear at the ends of interferograms
    # Get a value for the centre burst signal
    # (in this case s(quared as the interference can be negative)
    mid_value = max((interferogram[400:-400]) ** 2)
    # Check if any of the values are larger than the centre burst value
    # the extremes of the interferogram can contain very high values
    # that are rubbish
    clean = np.all(interferogram ** 2 < mid_value * 1.1)

    # If the interferogram is not clean, remove values in lots of
    # 100 from the end untill it is
    while not clean:
        interferogram = interferogram[100:-100]
        clean = np.all(interferogram ** 2 < mid_value * 1.1)

    # Find an estimate of the DC offset and remove from interferogram
    offset = np.mean(interferogram)
    interferogram = interferogram - offset

    # Find index of centre burst
    centre_burst_index = np.argmax(interferogram ** 2)

    # Set number of samples for padded array
    padded_int = np.zeros(padded_samples)

    # Fold out (from zpd) and copy the full/clipped input interferogram
    # ready for FFT (full_spe) FFT(apodised_spe)
    # and FFT(for phase determination)
    # Figure out the array index extent within the padded int to place
    # the zpd to +L of input interferogram
    padded_int[0:centre_burst_index] = interferogram[centre_burst_index:0:-1]
    int_to_copy = interferogram[:centre_burst_index:-1]
    padded_int[-len(int_to_copy):] = int_to_copy

    # Fourier transform the padded interferogram
    full_spe = fft(padded_int)

    # Truncate full frequency interferogram based on OPD
    truncation = round(OPD / HeNe)
    apodised_int = padded_int.copy()
    apodised_int[truncation:-truncation] = 0

    apodised_spe = fft(apodised_int)

    # Calculate low res interferogram for phase correction
    low_res_int = padded_int.copy()
    low_res_int[low_res_trunk:-low_res_trunk] = 0

    low_spe = fft(low_res_int)
    phase = np.arctan(np.imag(low_spe) / np.real(low_spe))

    # Create arrays for output interferograms
    constrained_samps = round(2500.0 / fre_interval)
    full_spectrum = np.empty((4, constrained_samps))
    apodised_spectrum = np.empty((4, constrained_samps))

    # Perform the phase correction
    corr_full_r, corr_full_i, full_phase = correct_spectrum(full_spe, phase)
    full_spectrum[0, :] = full_fre[0:constrained_samps]
    full_spectrum[1, :] = corr_full_r[0:constrained_samps]
    full_spectrum[2, :] = corr_full_i[0:constrained_samps]
    full_spectrum[3, :] = full_phase[0:constrained_samps]

    corr_ap_r, corr_ap_i, ap_phase = correct_spectrum(apodised_spe, phase)
    apodised_spectrum[0, :] = full_fre[0:constrained_samps]
    apodised_spectrum[1, :] = corr_ap_r[0:constrained_samps]
    apodised_spectrum[2, :] = corr_ap_i[0:constrained_samps]
    apodised_spectrum[3, :] = ap_phase[0:constrained_samps]

    return apodised_spectrum, full_spectrum


def correct_spectrum(complex_int, phase):
    """Perform Mertz phase correction

    Args:
        complex_int (complex_array): Complex interferogram
        phase (array): phase angle (will be interpolated
        onto interferogram)

    Returns:
        array: real part of corrected spectrum
        array: imaginary parf of corrected spectrum
        array: phase angle interpolated onto spectrum
    """
    phase_interped = np.interp(
        range(len(complex_int)), np.linspace(
            0, len(complex_int), len(phase)), phase
    )
    corr_specr = -(
        (np.real(complex_int) * np.cos(phase_interped))
        + (np.imag(complex_int) * np.sin(phase_interped))
    )
    corr_speci = -(
        np.real(complex_int) * np.cos(1.5708 - phase_interped)
        - np.imag(complex_int) * np.sin(1.5708 - phase_interped)
    )
    return corr_specr, corr_speci, phase_interped


def calculate_response_function(
    int_HBB,
    int_CBB,
    temp_HBB,
    temp_CBB,
    resolution=0.5,
    fre_interval=0.01,
    low_res_trunk=16384,
):
    """Calculate FINESSE response function

    Args:
        int_HBB (array): interferogram for HBB
        int_CBB (array): interferogram for CBB
        temp_HBB (float): temperature of HBB (C)
        temp_CBB (float): temperature of CBB (C)
        resolution (float, optional): resolution of output response function.
            Defaults to 0.5.
        fre_interval (float, optional): output grid spacing for response function.
            Defaults to 0.01.
        low_res_trunk (int, optional): number of points to take
        when calculating phase angle. Defaults to 16384.

    Returns:
        array: wavenumber scal (cm-1)
        array: response function calculated using apodised spectra
        array: response function calculated using full spectra
    """
    int_resp = int_HBB - int_CBB
    apodised_spectrum, full_spectrum = finesse_fft(
        int_resp, resolution, fre_interval, low_res_trunk
    )
    l_HBB = planck(apodised_spectrum[0, :], temp_HBB)
    l_CBB = planck(apodised_spectrum[0, :], temp_CBB)
    apodised_response = apodised_spectrum[1, :] / (l_HBB - l_CBB)
    full_response = full_spectrum[1, :] / (l_HBB - l_CBB)
    return apodised_spectrum[0, :], apodised_response, full_response


def colocate_time_range_gui(gui_data, times, variable):
    """Find and average data from the gui between given
    times

    Args:
        gui_data (Pandas Dataframe): GUI data loaded using
        load_gui_data
        times (tuple or list): Start and end times of interest
        in seconds since midnight
        variable (string): variable to colocate

    Returns:
        float: mean value of variable within time bounds
        float: standard devitaion of variable within
        time bounds
    """
    gui_index_start = gui_data["time"].sub(times[0]).abs().idxmin()
    gui_index_end = gui_data["time"].sub(times[1]).abs().idxmin()
    variable = gui_data.loc[gui_index_start:gui_index_end, variable]
    return np.mean(variable), np.std(variable)


def colocate_time_range_list(time_list, variable_list, times):
    """Find and average data from lists between given
    times

    Args:
        time_list (list, tuple, np.array): list of times coresponding
        to data to colocate
        variable_list: (list, tuple, np.array): data to colocate
        times (tuple or list): Start and end times of interest
        in seconds since midnight

    Returns:
        float: mean value of variable within time bounds
        float: standard devitaion of variable within
        time bounds
    """
    time_list = np.array(time_list, dtype=float)
    variable_list = np.array(variable_list, dtype=float)
    index_start = (np.abs(time_list - times[0])).argmin()
    index_end = (np.abs(time_list - times[1])).argmin()
    variables_needed = variable_list[index_start:index_end]
    return np.mean(variables_needed), np.std(variables_needed)


def calibrate_spectrum(
    int_scene,
    int_HBB,
    int_CBB,
    temp_HBB,
    temp_CBB,
    resolution=0.5,
    fre_interval=0.01,
    low_res_trunk=16384,
    NESR_number=20,
):
    """Calibrate scene view using interferogram method

    Args:
        int_scene (np.array): interferogram of scene view
        int_HBB (np.array): interferogram of HBB
        int_CBB (np.array): interferogram of CBB
        temp_HBB (float): temperature of HBB (degC)
        temp_CBB (float): temperature of CBB (degC)
        resolution (float, optional): Resolution of output spectrum.
            Defaults to 0.5.
        fre_interval (float, optional): Frequency grid for output
            spectrum. Defaults to 0.01.
        low_res_trunk (int, optional): Number of points used to calculate
            phase angle. Defaults to 16384.
        NESR_number (int, optional): Number of points used in rolling
            window to calculate NESR. Defaults to 20.

    Returns:
        np.array: wavenumber scale (cm-1)
        np.array: radiance (W/m^2/sr/cm-1)
        np.array: NESR (W/m^2/sr/cm-1)
    """
    wn, resp, _ = calculate_response_function(
        int_HBB, int_CBB, temp_HBB, temp_CBB, resolution, fre_interval, low_res_trunk
    )
    # Calculate spectrum of scene minus HBB
    spectrum_scene, _ = finesse_fft(
        int_scene - int_HBB, resolution, fre_interval, low_res_trunk
    )

    # Check wn scales are the same
    if not np.all(wn == spectrum_scene[0, :]):
        print("Wn scales different something is wrong")
        return None

    L_HBB = planck(wn, temp_HBB)

    rad_scene = (spectrum_scene[1, :] / resp) + L_HBB

    # Calculate NESR from imaginary part of corrected spectrum
    print('Using old method to calculate NESR - see comment in code')
    # NESR should be calculated by comparing consecutive spectra of the same scene (see Jon's paper)
    # This script is for a single spectra and so this cannot be easily done
    # Instead write an additional function to calculate the residuals between consecutive spectra 
    # And fill nesr with nans
    rad_NESR = spectrum_scene[2, :] / resp
    rad_NESR = pd.DataFrame(rad_NESR, columns=["rad"])
    NESR = rad_NESR.rad.rolling(NESR_number).std()

    NESR[:]=np.nan

    return wn, rad_scene, NESR


def calibrate_spectrum_with_cal_error(
    int_scene,
    int_HBB,
    int_CBB,
    temp_HBB,
    temp_CBB,
    HBB_error,
    CBB_error,
    resolution=0.5,
    fre_interval=0.01,
    low_res_trunk=16384,
    NESR_number=20,
):
    """Calibrate scene view using interferogram method and calculate
    calibration error

    Args:
        int_scene (np.array): interferogram of scene view
        int_HBB (np.array): interferogram of HBB
        int_CBB (np.array): interferogram of CBB
        temp_HBB (float): temperature of HBB (degC)
        temp_CBB (float): temperature of CBB (degC)
        HBB_error (float): error in HBB temperature sensors
        CBB_error (float): error in CBB temperature sensors
        resolution (float, optional): Resolution of output spectrum.
            Defaults to 0.5.
        fre_interval (float, optional): Frequency grid for output
            spectrum. Defaults to 0.01.
        low_res_trunk (int, optional): Number of points used to calculate
            phase angle. Defaults to 16384.
        NESR_number (int, optional): Number of points used in rolling
            window to calculate NESR. Defaults to 20.

    Returns:
        np.array: wavenumber scale (cm-1)
        np.array: radiance (W/m^2/sr/cm-1)
        np.array: NESR (W/m^2/sr/cm-1)
        tuple: upper/lower calibration error (W/m^2/sr/cm-1)
    """
    wn, rad, NESR = calibrate_spectrum(
        int_scene,
        int_HBB,
        int_CBB,
        temp_HBB,
        temp_CBB,
        resolution=resolution,
        fre_interval=fre_interval,
        low_res_trunk=low_res_trunk,
        NESR_number=NESR_number,
    )
    _, rad_high, _ = calibrate_spectrum(
        int_scene,
        int_HBB,
        int_CBB,
        temp_HBB - HBB_error,
        temp_CBB + CBB_error,
        resolution=resolution,
        fre_interval=fre_interval,
        low_res_trunk=low_res_trunk,
        NESR_number=NESR_number,
    )
    _, rad_low, _ = calibrate_spectrum(
        int_scene,
        int_HBB,
        int_CBB,
        temp_HBB + HBB_error,
        temp_CBB - CBB_error,
        resolution=resolution,
        fre_interval=fre_interval,
        low_res_trunk=low_res_trunk,
        NESR_number=NESR_number,
    )
    plus_cal_error = rad_high - rad
    minus_cal_error = rad - rad_low
    return wn, rad, NESR, (plus_cal_error, minus_cal_error)


def seconds_to_time(seconds):
    """Convert seconds since midnight to time
    in the format HHMM rounded to the nearest minute

    Args:
        seconds (float): Seconds since midnight

    Returns:
        string: time in the format HHMM
    """
    hours_raw = seconds / 3600.0
    hours = floor(hours_raw)
    minutes_raw = hours_raw - hours
    minutes = np.round(minutes_raw * 60)
    time = "%02d%02d" % (hours, minutes)
    return time


def ppm_to_ppmv(ppm, ppmv_water):
    """Convert ppm in dry air to ppmv

    Args:
        ppm (float): ppm in dry air
        ppmv_water (float): ppmv of water vapour in air

    Returns:
        float: ppmv of gas in specified atmosphere
    """
    ppmv = ppm * ((1e6 - ppmv_water) / 1e6)
    return ppmv


def mr_to_vmr(dropsonde_mr):
    """Convert mr to vmr for water vapour

    Args:
        dropsonde_mr (floar or array): mass mixing ratio in g/kg

    Returns:
        float or array: volume mixing ratio ppmv
    """
    dropsonde_mr_kg = dropsonde_mr / 1000.0  # Convert from g/kg to kg/kg
    dropsonde_h2o = (28.9644 / 18.01528) * 1.0e6 * dropsonde_mr_kg
    return dropsonde_h2o


def rh_to_vmr(rh, T, P):
    """
    Coverts from relative humidity to volume mixing ratio in ppmv
    :param rh: float or array - the relative humidity
    :param T: float or array - temperature in Kelvin
    :param P float or array - pressure in hPa
    :return:
    vmr - volume mixing ration ppmv
    """
    # Calculate saturation vapour pressure from temperature from
    # https://ncar.github.io/aspendocs/form_esw_hardy.html
    g0 = -2.8365744e3
    g1 = -6.028076559e3
    g2 = 1.954263612e1
    g3 = -2.737830188e-2
    g4 = 1.6261698e-5
    g5 = 7.0229056e-10
    g6 = -1.8680009e-13
    g = [g0, g1, g2, g3, g4, g5, g6]
    lnEsw = 2.7150305 * np.log(T)
    for i in range(len(g)):
        lnEsw += g[i] * (T ** (i - 2))
    Esw = np.exp(lnEsw)
    Esw = Esw / 100

    # Calculate vapour pressure
    E = (rh / 100) * Esw

    # Covert vapour pressure to mass mixing ratio
    w = 0.622 * (E / (P - E)) * 1000

    # Convert to vmr
    vmr = mr_to_vmr(w)

    return vmr


def load_transmission(
    filename, version=None, load_trans=True, load_info=True, error=False
):
    """Load transmission and header files created using
       5_calculate_transmission.py and TAPE12 files extracted using IDL

    Args:
        filename (string): filename from transmission file
        version (string, optional): If None, load the
            raw version of the tranmsission file, if a string, load the
            version of transmission specified by that string.
            Defaults to None.
        load_trans (bool, optional): If True transmission data is loaded.
            Defaults to True.
        load_info (bool, optional): If True auxilary data is loaded from
            the header file. Defaults to True.

    Returns:
        if load_trans AND load_info
        np.array: wavenumber scale (cm-1)
        np.array: transmission
        dict    : auxilary data including (if not error)
                "scene_times" (list) start and end times for transmission
                    including calibration cycles
                    (seconds since midnight)
                "scene_name" (int) name of scene view
                "sky_name" (int) name of sky view
                "path_length" (float) length of transmission path (km)
                "pressure" (float) ambient pressure during scene view (hPa)
                "pressure_std" (float) standard deviation in pressure during
                    scene view (hPa)
                "temp" (float) ambient temp during scene view (C)
                "temp_std" (float) standard deviation in temp during
                    scene view (C)
                "humidity" (float) ambient humidity during scene view (%%RH)
                "humidity_std" (float) standard deviation in humidity during
                    scene view (%%RH)
                "co2" (float) ambient co2 during scene view (ppm (dry air))
                "co2_std" (float) standard deviation in co2 during
                    scene view (ppm (dry air))
                "time" (float) average time of scene view
                    (seconds since midnight)
    """
    if load_info:
        filename_split = filename.split(".")
        filename_header = filename_split[0] + "_header.txt"
        with open(filename_header, "r") as f:
            if error:
                for i, line in enumerate(f):
                    if i == 2:
                        error_raw = line
                    if i == 5:
                        times_raw = line
                    if i == 7:
                        path_raw = line
                    if i == 9:
                        pressure_raw = line
                    if i == 11:
                        temp_raw = line
                    if i == 13:
                        humidity_raw = line
                    if i == 15:
                        co2_raw = line
                    if i > 15:
                        break
            else:
                for i, line in enumerate(f):
                    if i == 2:
                        scene_raw = line
                    if i == 3:
                        sky_raw = line
                    if i == 5:
                        times_raw = line
                    if i == 7:
                        path_raw = line
                    if i == 9:
                        pressure_raw = line
                    if i == 11:
                        temp_raw = line
                    if i == 13:
                        humidity_raw = line
                    if i == 15:
                        co2_raw = line
                    if i > 15:
                        break
        times = times_raw.split(" ")
        path = path_raw.split(" ")[0]
        pres, pres_error = pressure_raw.split(" +/- ")
        temp, temp_error = temp_raw.split(" +/- ")
        humidity, humidity_error = humidity_raw.split(" +/- ")
        co2, co2_error = co2_raw.split(" +/- ")
        time = (float(times[0]) + float(times[1][:-1])) / 2
        data = {
            "scene_times": [float(times[0]), float(times[1][:-1])],
            "path_length": float(path),
            "pressure": float(pres),
            "pressure_std": float(pres_error[:-1]),
            "temp": float(temp),
            "temp_std": float(temp_error[:-1]),
            "humidity": float(humidity),
            "humidity_std": float(humidity_error[:-1]),
            "co2": float(co2),
            "co2_std": float(co2_error[:-1]),
            "time": time,
        }
        if error:
            error_float = float(error_raw.split(" ")[-2])
            data["error"] = error_float
        else:
            scene = scene_raw.split(":")[-1]
            sky = sky_raw.split(":")[-1]
            data["scene_name"] = int(scene)
            data["sky_name"] = int(sky)
    if isinstance(version, str):
        filename_split = filename.split("/")
        filename = "/".join(filename_split[:-1]) + "/%s/%s" % (
            version,
            filename_split[-1],
        )
    if load_trans:
        wn, trans = np.loadtxt(filename, unpack=True)
    if load_trans and load_info:
        return wn, trans, data
    elif load_trans:
        return wn, trans
    else:
        return data


def all_equal(iterator):
    """Check if all np arrays in list are equal
    from stackexchange "Check if list of numpy arrays are equal"

    Args:
        iterator (list): List of arrays

    Returns:
        bool: True if all arrays are equal
    """
    try:
        iterator = iter(iterator)
        first = next(iterator)
        return all(np.array_equal(first, rest) for rest in iterator)
    except StopIteration:
        return True


def apodise_spectrum(
    frequency,
    radiance,
    fre_grid,
    st,
    ed,
    new_pd,
    apodisation_func=False,
    test_delta=False,
):
    """
    Apodise a high resolution spectrum using a boxcar or
    triangle function

    Adapted from apodise_spectra_boxcar_v1.pro
    ;
    ; Original Author: J Murray (14-Oct-2020)
    ;
    ; Additional comments by R Bantges
    ; Version 1: Original
    ;
    ; Requirements:
    ; [1] high resolution radiance or transmission spectrum
    ;
    ; Input variables:
    ; [1] filename: TAPES12 filename including path
    ; [2] radiance: Variable name for the radiance output
    ; [3] frequency: Variable name for the frequency output
    ; [4] nwave_lblrtm: Total number of points in radiance output
    ; [5] file_type: 1 or 2 for radiance or transmission (if transmission the radiance variable above will contain transmission values
    ; [6] st: TAPE12 simulation start wavenumber
    ; [7] ed: TAPE12 simulation end wavenumber
    ; [8] new_pd: extent of boxcar path difference (cm)
    ;
    ; Outputs:
    ; [1] apodised_spectra  the boxcar apodies ouput spectra
    ;
    ; Notes:
    ; [1]
    ;
    ; Updates:
    ; [1] Amended '(' where referring to an array index to '[' for IDL COMPILE OPT STRICT  (R Bantges)
    ; [2] Added CASE statement to specify whether LBLRTM TAPE12 output is in single or double precision (R Bantges)
    ; [3] Converted to Python (L Warwick)
    ; [4] Adapted to work with wn and spectrum that are already loaded

    Params
    ------
    frequency array
        Original wavenumber scale (cm^-1)
    radiance array
        Original spectrum
    fre_grid float
        The frequency of the  output grid for the apodised spectra (cm^-1)
    st float
        Wavenumber to start apodised spectrum (cm^-1)
    ed float
        Wavenumber to end apodised spectrum (cm^-1)
    new_pd float
        Optical path difference i.e. width of boxcar to apodise (cm)
    apodisation_func string
        deafult=False
        Function to use in addition to boxcar to apodise the spectrum
        Options
        -------
        "triangle" - Triangle function, running from 1 at centre of interferogram
        to zero at edge of interferogram
    test_delta bool
        deafult=False
        If True, the spectrum is taken to be a delta function, can be
        used to test the apodisation
        If False input spectrum is used

    Returns
    -------
    wn array
        Wavenumber of apodised spectrum (cm^-1)
    radiance array
        Radiance or transmission of apodised spectrum
        (same units as input)
    """
    # Determine the number of samples making up the output spectra
    samples = int(np.round((ed - st) / fre_grid))

    # Define the wavenumber grid resolution (Fixed high resolution grid.
    # The Monochromatic spectra will be interpolated onto this grid for
    # convenience and potentially reduce time taken for the FFT, the arbitrary
    # number of points in the spectra can be such that it significantly slows
    # the FFT.
    # NB: 0.0001 cm-1 was chosen to resolve the spectral features in the
    # high resolution simulation
    dum_new_res = 0.0001
    dum_samples = int(np.round((ed - st) / dum_new_res))
    # The number of samples in the high res frequency scale

    # ********** Define the arrays for the re-interpolated radiance files **********
    # generate a wavenumber scale running from st - ed wavenumbers
    # at new_res cm-1
    new_fre = np.arange(st, ed, fre_grid)
    # generate a wavenumber scale running from st - ed wavenumbers at 0.001 cm-1
    dum_new_fre = np.arange(st, ed, dum_new_res)
    # ******************************************************************************

    # ********** Interpolate the high res radiance to new array scales **********
    f_dum_spec = interp1d(frequency, radiance)
    dum_spec = f_dum_spec(dum_new_fre)
    if test_delta:
        dum_spec = np.zeros_like(
            dum_spec
        )  # These can be set to produce a delta function to check the sinc
        dum_spec[int(15000000 / 2): int(15000000 / 2) + 101] = 100.0
    # *****************************************************************************

    # FFT the interpolated LBLRTM spectrum
    int_2 = fft(dum_spec)
    # sampling=1./(2*0.01)/samples/100.   # Sampling interval of the interferogram in cm these are the same for the 0.001 and 0.01 spectra
    sampling = 1.0 / (2 * fre_grid) / samples / 100.0
    # Sampling interval of the interferogram in cm these are the same for the 0.001 and 0.01 spectra

    # ********** Apodise the LBLRTM sim and transform **********
    Q = int(
        round(new_pd / 100.0 / sampling / 2.0)
    )  # number of samples required to extend the path difference to 1.26cm
    # *****************************************************************************

    # Define an array to hold the folded out inteferogram
    int_1 = np.zeros(samples, dtype=np.cdouble)

    # 'int_2' - this interferogram is equivalent to a sampling grid of 0.001 cm-1
    # in the spectral domain, this statement applies a boxcar apodisation over +/-1.26 cm
    int_2[Q:-Q] = 0.0

    # The following two lines reduce the output spectra to a sampling grid of 0.01 cm-1
    # while copying in the truncated interferogram from the high resolution interferogram
    int_1[0: int(round((samples / 2)))] = int_2[0: int(round((samples / 2)))]
    int_1[int(round((samples / 2))): samples] = int_2[
        (dum_samples) - int(round((samples / 2))): dum_samples
    ]

    if apodisation_func == "triangle":
        print("Apodising with triangle")
        int_1_unapodised = np.copy(int_1)
        triangle_left = [1, 0]
        triangle_left_x = [0, Q]
        triangle_left_x_all = np.arange(len(int_1[0:Q]) + 1)
        f_triangle_left = interp1d(triangle_left_x, triangle_left)
        triangle_right = [0, 1]
        triangle_right_x = [len(int_1) - Q - 1, len(int_1)]
        triangle_right_x_all = np.arange(len(int_1) - Q - 1, len(int_1), 1)
        f_triangle_right = interp1d(triangle_right_x, triangle_right)

        int_1[0: Q + 1] = int_1[0: Q + 1] * \
            f_triangle_left(triangle_left_x_all)
        int_1[-Q - 2: -1] = int_1[-Q - 2: -1] * \
            f_triangle_right(triangle_right_x_all)

    elif not apodisation_func:
        print("Apodising with boxcar")

    else:
        print("No recognised function selected, defaulting to boxcar")

    new_lbl_spec = ifft(int_1)

    # ***********************************************************************
    apodised_spectra = np.real(new_lbl_spec / (fre_grid / dum_new_res))
    return new_fre, apodised_spectra


def calculate_emissivity_constant_atm(wn, L_up, L_down, trans, T_a, T_s):
    """
    Calculate emissivity from up and down welling radiation,
    surface temperature and atmospheric transmission
    This calculation assumes the atmosphere has a constant temperature
    Use method from Newman paper

    Params
    ------
    wn array
        Wavenumbers
        (cm^-1)
    L_up array
        Upwelling radiance
        (W / (m^{2} sr^{1} cm^{-1}))
    L_down array
        Downwelling radiance
        (W / (m^{2} sr^{1} cm^{-1}))
    trans array
        Transmission between the surface and detector
        (arbitrary)
    T_a float
        Temperature of the atmosphere
        (degC)
    T_s float
        Temperature of the surface
        (degC)

    Returns
    -------
    emiss array
        Emissivity at each wavenumber
    """
    B_atm = planck(wn, T_a)
    B_surf = planck(wn, T_s)
    Top = L_up - trans ** (2.0) * L_down - ((1) - trans ** (2.0)) * B_atm
    Bottom = trans * (B_surf - trans * L_down - ((1) - trans) * B_atm)
    emiss = Top / Bottom
    return emiss


def planck_from_emissivity(emiss, wn, L_up, L_down, trans, T_a):
    """
    Calculate Planck's function given emissivity and radiance
    using eq. 5 from Newman paper
    Params
    ------
    emiss float
        Emissivity
    wn array
        Wavenumbers
        (cm^-1)
    L_up array
        Upwelling radiance
        (W / (m^{2} sr^{1} cm^{-1}))
    L_down array
        Downwelling radiance
        (W / (m^{2} sr^{1} cm^{-1}))
    trans array
        Transmission between the surface and detector
        (arbitrary)
    T_a float
        Temperature of the atmosphere
        (degC)

    Returns
    -------
    Planck array
        Planck function inferred from eq. 5
        (W / (m^{2} sr^{1} cm^{-1}))
    """
    B_atm = planck(wn, T_a)
    T = L_up - trans ** 2 * L_down - (1 - trans ** 2) * B_atm
    B_surface = T / (emiss * trans) + trans * L_down + (1 - trans) * B_atm
    return B_surface


def retrieve_surface_temperature(
    wn_spectrum, L_up, L_down, wn_trans, trans, T_a, plot=False, verbose=False
):
    """
    Retrieve the surface temperature of water using up and downwelling
    measurements of radiance.
    Prarams
    -------
    wn_spectrum array
        wavenumbers of spectrum at detector
        (cm^-1)
    L_up array
        upwelling spectrum at detector
        (W / (m^{2} sr^{1} cm^{-1}))
    L_down array
        downwelling spectrum at detector
        (W / (m^{2} sr^{1} cm^{-1}))
    wn_trans array
        wavenumbers of transmission between surface and detector
        (cm^-1)
    trans array
        transmission between surface and detector
    T_a float
        temperature of the atmosphere between the surface
        and detector
        (degrees C)

    Returns
    -------
    surface_temp float
        temperature of the surface
        (degrees C)
    surface_temp_std float
        standard deviation of the surface temperature
        retrieval from different wavebands
        (degrees C)
    """
    # Interpolate transmission onto upwelling spectrum
    f_trans = interp1d(wn_trans, trans)
    trans = f_trans(wn_spectrum)

    # Split spectrum up into chunks of 40 cm^-1
    wn_step = np.average(np.diff(wn_spectrum))
    n_step = int(np.round(40 / wn_step))
    n_chunks = int(len(wn_spectrum) / n_step)
    wns = []
    emissivity = []
    temperature = []
    # for i in range(n_chunks):
    if plot:
        fig1, ax1 = plt.subplots(1, 1)
    for i in range(n_chunks):
        if verbose:
            print(
                "Wavenumbers: ",
                wn_spectrum[i * n_step],
                wn_spectrum[((i + 1) * n_step) - 1],
            )
        wn_chunk = wn_spectrum[i * n_step: ((i + 1) * n_step) - 1]
        wns.append(np.average(wn_chunk))
        L_up_chunk = L_up[i * n_step: ((i + 1) * n_step) - 1]
        L_down_chunk = L_down[i * n_step: ((i + 1) * n_step) - 1]
        trans_chunk = trans[i * n_step: ((i + 1) * n_step) - 1]
        p_minimised = minimize_scalar(
            surface_temp_to_minimise,
            args=(wn_chunk, L_up_chunk, L_down_chunk, trans_chunk, T_a),
        )
        e_chunk = 1 - p_minimised.x
        if verbose:
            print("Emissivity: ", e_chunk)
        B_surface = planck_from_emissivity(
            e_chunk, wn_chunk, L_up_chunk, L_down_chunk, trans_chunk, T_a
        )
        if plot:
            pass
            # ax1.scatter(np.average(wn_chunk), e_chunk)
        if plot:
            ax1.plot(wn_chunk, B_surface)
        surf_temp = curve_fit(planck, wn_chunk, B_surface, p0=[T_a])
        if verbose:
            print("Surface temperature: %.6f +/- %.6f" %
                  (surf_temp[0], surf_temp[1]))
        emissivity.append(e_chunk)
        temperature.append(surf_temp[0])
    return wns, emissivity, temperature


def retrieve_temp_jon(
    wn, L_up, L_down, trans, T_a,
    T_bounds, wn_bounds, wn_step_size=40, verbose=False,
    step_size=0.1
):
    """
    Jointly retrieve emissivity and surface temperature from up and 
    downwelling radiation, atmospheric temperature and atmospheric
    transmission.
    This calculation assumes the atmosphere has a constant
    temperature
    This method has been developed by Jon.
    The retrieval will run for surface
    temperatures in steps of 0.1 degrees between T_start and T_end.
    The returned retrieval will be the one that minimised
    the standard deviation in emissivity
    between the wavenumber bounds

    Params
    ------
    wn array
        Wavenumbers
        (cm^-1)

    L_up array
        Upwelling radiance
        (W / (m^{2} sr^{1} cm^{-1}))

    L_down array
        Downwelling radiance
        (W / (m^{2} sr^{1} cm^{-1}))

    trans array
        Transmission between the surface and detector
        (arbitrary)

    T_a float
        Temperature of the atmosphere
        (degC)

    T_bounds list [T_start, T_end]
        Temperatures over which to perform minimisation
        (deg C)

    wn_bounds list [wn_start, wn_end]
        Wavenumbers over which to perform minimisation
        (cm^-1)

    verbose bool deafult=False
        If True returns all the surface temperatures and
        standard deviations tested

    step_size float deafult=0.1
        Size of steps for surface temperature
        (deg C)

    Returns
    -------
    T_surf
        Surface temperature
        (deg C)

    If verbose=True
    std_deviations array
        Row 0 is the temperatures tested
        (deg C)
        Row 1 is the standard deviation
        across the wn range
        (deg C)
    """
    # Find index for wns of interest
    wn_idx = np.logical_and(wn >= wn_bounds[0], wn <= wn_bounds[1])
    temps = np.arange(T_bounds[0], T_bounds[1], step_size)
    wn = wn[wn_idx]
    L_up = L_up[wn_idx]
    L_down = L_down[wn_idx]
    trans = trans[wn_idx]
    wn_step = np.average(np.diff(wn))
    n_step = int(np.round(40 / wn_step))
    n_chunks = int(len(wn) / n_step)
    wns = []
    temperature = []
    std = np.empty((n_chunks, len(temps), 2))
    # for i in range(n_chunks):
    for i in range(n_chunks):
        std_chunk = []
        # if verbose:
        #     print(
        #         "Wavenumbers: ",
        #         wn[i * n_step],
        #         wn[((i + 1) * n_step) - 1],
        #     )
        wn_chunk = wn[i * n_step: ((i + 1) * n_step) - 1]
        wns.append(np.average(wn_chunk))
        L_up_chunk = L_up[i * n_step: ((i + 1) * n_step) - 1]
        L_down_chunk = L_down[i * n_step: ((i + 1) * n_step) - 1]
        trans_chunk = trans[i * n_step: ((i + 1) * n_step) - 1]
        for j, temp in enumerate(temps):
            emis_temp = calculate_emissivity_constant_atm(
                wn_chunk,
                L_up_chunk,
                L_down_chunk,
                trans_chunk,
                T_a,
                temp
            )
            std_temp = np.std(emis_temp)
            std_chunk.append(std_temp)
            std[i, j, 0] = temp
            std[i, j, 1] = std_temp
        min_index = np.argmin(std_chunk)
        T_surf = temps[min_index]
        temperature.append(T_surf)
    std_out = np.average(std, axis=0)
    if verbose:
        return np.average(temperature), np.std(temperature), wns, temperature, std_out
    else:
        return np.average(temperature), np.std(temperature)


def surface_retrieval_equation(p, wn, L_up, L_down, trans, T_a):
    half_1 = (1 / trans) * (L_up - (1 - trans) * planck(wn, T_a))
    half_2 = p * (trans * L_down + (1 - trans) * planck(wn, T_a))
    answer = half_1 - half_2
    return answer


def surface_temp_to_minimise(p, wn, L_up, L_down, trans, T_a):
    guess_of_function = surface_retrieval_equation(
        p, wn, L_up, L_down, trans, T_a)
    quadratic_fit = np.polyfit(wn, guess_of_function, 2)
    quadratic_function = np.poly1d(quadratic_fit)
    quadratic = quadratic_function(wn)
    rms_difference = np.sqrt(np.mean((guess_of_function - quadratic) ** 2))
    return rms_difference


def fresnel_jon(n, k, theta):
    """Calculate fresnel reflectance. Adapted from Jon's
    IDL code.

    Args:
        n (float or array): Real part of refractive index
        k (float or array): Complex part of refractive index
        theta (float): Angle of incidence

    Returns:
        float or array: emissivity
        float or array: Parallel reflectance
        float or array: Perpendicular reflectance
    """
    a2 = (
        n ** 2
        - k ** 2
        - np.sin(theta) ** 2
        + np.sqrt((n ** 2 - k ** 2 - np.sin(theta) ** 2)
                  ** 2 + 4 * n ** 2 * k ** 2)
    ) / 2
    b2 = (
        k ** 2
        - n ** 2
        + np.sin(theta) ** 2
        + np.sqrt((n ** 2 - k ** 2 - np.sin(theta) ** 2)
                  ** 2 + 4 * n ** 2 * k ** 2)
    ) / 2

    # Perpendicular
    RS = (a2 + b2 - 2.0 * np.sqrt(a2) * np.cos(theta) + np.cos(theta) ** 2) / (
        a2 + b2 + 2.0 * np.sqrt(a2) * np.cos(theta) + np.cos(theta) ** 2
    )

    # Parallel
    RP = RS * (
        (
            a2
            + b2
            - 2.0 * np.sqrt(a2) * np.sin(theta) * np.tan(theta)
            + np.sin(theta) ** 2 * np.tan(theta) ** 2
        )
        / (
            a2
            + b2
            + 2.0 * np.sqrt(a2) * np.sin(theta) * np.tan(theta)
            + np.sin(theta) ** 2 * np.tan(theta) ** 2
        )
    )

    emissivity = 1 - (RP + RS) / 2

    return emissivity, RP, RS


def zg_to_z(zg, approx=True):
    """Convert from geopotential height to height

    Args:
        zg (float or array): geopotential height
        approx (bool, optional): Allow approximation. Defaults to True.

    Returns:
        float or array: height (m)
    """      
    Re = 6371e3  # in m
    zg = zg/9.80665
    if approx:
        bracket = (1 - (2*zg)/Re)
        z = zg / bracket
    else:
        print("This is not written yet")
        z = None
    return z/1000


def apply_ILS_sav(ILS, start_fre, end_fre, wn,
                  spectrum, pad_length=10):
    """Apply ILS to a spectrum

    Args:
        ILS (array (ILS, frequency bin)): ILS axis 0 is the
            ILS axis 1 is the frequency bin as defined by 
            start_fre, end_fre
        start_fre (array): Start frequency for wn bin (cm-1)
        end_fre (array): end frequency for wn bin (cm-1)
        wn (array): wn scale of spectrum (cm-1)
        spectrum (array): spectrum
        padlength (int): amount to add to end of each wavenumber
            section to remove edge effects. Expressed in units of
            wavenumber
    """
    # Specify frequency scale of ILS
    ILS_frequency_scale = np.linspace(
        -5, 5, np.shape(ILS)[0]
    )

    # Loop through each chunk of spectrum and apply the ILS
    # to that chunk
    for i in range(len(start_fre)):
        # , END_WN, ils_now in zip(
        #     ILS["start_fre_range"],
        #     ILS["end_fre_range"],
        #     ILS["ils_function"],
        # ):
        # Trim to correct chunk of spectrum
        # Add extra for convolution overlap
        index = np.where(
            np.logical_and(
                wn >= start_fre[i] -
                pad_length,
                wn <= end_fre[i] +
                pad_length,
            )
        )
        wn_now = wn[index]
        spectrum_now = spectrum[index]
        # Interpolate ILS onto frequency of signal
        ILS_frequency_scale_interp = np.arange(
            -5,
            5,
            np.average(np.diff(wn_now))
        )
        ils_now_interp = np.interp(
            ILS_frequency_scale_interp,
            ILS_frequency_scale,
            ILS[:, i]
        )
        spectrum_interp = np.convolve(
            spectrum_now,
            ils_now_interp,
            mode="same",
        ) / sum(ils_now_interp)
        # Trim so only spectrum in area of interest is
        # retained
        index_out = index = np.where(
            np.logical_and(
                wn_now >= start_fre[i],
                wn_now < end_fre[i],
            )
        )
        wn_out = wn_now[index_out]
        spectrum_out = spectrum_interp[index_out]
        # plt.cla()
        # plt.plot(wn_now, spectrum_now)
        # plt.plot(wn_now, spectrum_interp)
        # plt.plot(wn_out, spectrum_out)
        # plt.savefig(
        #     "/net/shamal/disk1/lw2214/Water emissivity results/"
        #     + "Water 3/test_convolve_1.png")
        if i == 0:
            wn_all = wn_out
            spectrum_all = spectrum_out
        else:
            wn_all = np.append(wn_all, wn_out)
            spectrum_all = np.append(spectrum_all, spectrum_out)
    return wn_all, spectrum_all


def wl_to_wn(wl):
    """Convert wavelength in micrometers to
    wavenumber in inverse centimeters

    Args:
        wl (float or array): wavelength (micrometers)

    Returns:
        float or array: wavenumber (cm-1)
    """
    wl_cm = wl * 1e-4
    wn = 1/wl_cm
    return wn


def wn_to_wl(wn):
    """Convert wavenumber in inverse centimeters
    to wavelength in micrometers

    Args:
        wn (float or array): wavenumber (cm-1)

    Returns:
        float or array: wavelength (micrometers)
    """
    wl=10000 / wn
    return wl


def rad_to_bt(v_list , B_in):
    """Convert from radiance to BT. From Sanjee

    Args:
        v_list (array): wavenumber (cm-1)
        B_list (array): radiance (W/m2 sr cm-1)

    Returns:
        array: Brightness temperature (K)
    """
    B_list = B_in*1000
    c1=1.191044E-5
    c2 = 1.438769
    T = c2*v_list / np.log(c1*v_list**3/B_list +1)
    return T



def threshold_plot(ax, x, y, threshv, color, overcolor):
    """
    From https://stackoverflow.com/questions/30121773/python-is-it-possible-to-change-line-color-in-a-plot-if-exceeds-a-specific-rang
    Helper function to plot points above a threshold in a different color

    Parameters
    ----------
    ax : Axes
        Axes to plot to
    x, y : array
        The x and y values

    threshv : float
        Plot using overcolor above this value

    color : color
        The color to use for the lower values

    overcolor: color
        The color to use for values over threshv

    """
    # Create a colormap for red, green and blue and a norm to color
    # f' < -0.5 red, f' > 0.5 blue, and the rest green
    cmap = ListedColormap([color, overcolor])
    norm = BoundaryNorm([np.min(y), threshv, np.max(y)], cmap.N)

    # Create a set of line segments so that we can color them individually
    # This creates the points as a N x 1 x 2 array so that we can stack points
    # together easily to get the segments. The segments array for line collection
    # needs to be numlines x points per line x 2 (x and y)
    points = np.array([x, y]).T.reshape(-1, 1, 2)
    segments = np.concatenate([points[:-1], points[1:]], axis=1)

    # Create the line collection object, setting the colormapping parameters.
    # Have to set the actual values used for colormapping separately.
    lc = LineCollection(segments, cmap=cmap, norm=norm)
    lc.set_array(y)

    ax.add_collection(lc)
    ax.set_xlim(np.min(x), np.max(x))
    ax.set_ylim(np.min(y)*1.1, np.max(y)*1.1)
    return lc


def _newman_equation(index, coefficient, T):
    """Equations 8a and 8b from Newman paper

    Args:
        index (array or float): index at 0C
        coefficient (array or float): coefficients
        T (float): temperature

    Returns:
        _type_: _description_
    """
    return index + coefficient*T


def newman_temp(angle, T, wn, n_0, k_0, c_n, c_k):
    """Calculate emissivity using NEwman's temperature
    dependent refractive indices

    Args:
        angle (float): Angle to calculate emissivity (radiens)
        T (float): Temperature in C
        wn (list-like): Wavenumbers for refractive indices
        n_0 (list_like): Real part of refractive index at 0C
        k_0 (list_like): Imaginary part of refractive index at 0C
        c_n (list_like): Co-efficients for real part of refractive index
        c_k (list_like): Co-efficients for imaginary part of refractive index

    Returns:
        list_like: Emissivity
        list_like: Real part of refractive index at temperature T
        list_like: Imaginary part of refractive index at temperature T
    """
    n = _newman_equation(n_0, c_n, T)
    k = _newman_equation(k_0, c_k, T)
    emissivity, _, _ = fresnel_jon(n, k, angle)
    return emissivity, n, k


def quad_add(x, y):
    """Add a and y in quadrature

    Args:
        x (array or float): variable 1
        y (array or float): variable 2

    Returns:
        array or float: 1 and 2 added in quadrature
    """
    return np.sqrt(x**2 + y**2)


def load_transmission_min_max(
    filename_header, version=None
):
    """Load transmission and header files created using
       5_calculate_transmission.py and TAPE12 files extracted using IDL

    Args:
        filename (string): filename for header file
        version (string, optional): If None, load the
            raw version of the tranmsission file, if a string, load the
            version of transmission specified by that string.
            Defaults to None.
        load_trans (bool, optional): If True transmission data is loaded.
            Defaults to True.
        load_info (bool, optional): If True auxilary data is loaded from
            the header file. Defaults to True.

    Returns:
        if load_trans AND load_info
        np.array: wavenumber scale (cm-1)
        np.array: transmission
        dict    : auxilary data about the error
    """
    filename = filename_header[:-11] + ".txt"
    folder = filename[:-9]
    file_number = filename[-9:-4]
    with open(filename_header, "r") as f:
        for i, line in enumerate(f):
            if i == 2:
                scene_raw = line
            if i == 3:
                sky_raw = line
            if i == 5:
                times_raw = line
            if i == 7:
                path_raw = line
            if i == 8:
                pressure_raw = line
            if i == 9:
                temp_raw = line
            if i == 10:
                humidity_raw = line
            if i == 11:
                co2_raw = line
            if i > 12:
                break
    scene = int(scene_raw.split(":")[-1])
    sky = int(sky_raw.split(":")[-1])
    times = times_raw.split(" ")
    path_temp = path_raw.split("+")
    path = float(path_temp[0][:-3]) 
    path_error = float(path_temp[-1])
    pressure_raw = pressure_raw.split(" ")
    pres = float(pressure_raw[1][:-1])
    pres_sensor_error = float(pressure_raw[4][:-1])
    pres_variability = float(pressure_raw[6][:-1])
    pres_total_error = float(pressure_raw[9])
    temp_raw = temp_raw.split(" ")
    temp = float(temp_raw[2][:-1])
    temp_sensor_error = float(temp_raw[5][:-1])
    temp_variability = float(temp_raw[7][:-1])
    temp_total_error = float(temp_raw[10])
    humidity_raw = humidity_raw.split(" ")
    humidity = float(humidity_raw[1][:-1])
    humidity_sensor_error = float(humidity_raw[4][:-1])
    humidity_variability = float(humidity_raw[6][:-1])
    humidity_total_error = float(humidity_raw[9])
    co2_raw = co2_raw.split(" ")
    co2 = float(co2_raw[1][:-1])
    co2_sensor_error = float(co2_raw[4][:-1])
    co2_variability = float(co2_raw[6][:-1])
    co2_total_error = float(co2_raw[9])
    time = (float(times[0]) + float(times[1][:-1])) / 2
    data = {
        "scene_times": [float(times[0]), float(times[1][:-1])],
        "scene_name": scene,
        "sky_name": sky,
        "path_length": path,
        "path_total_error": path_error,
        "pres": pres,
        "pres_sensor_error": pres_sensor_error,
        "pres_var": pres_variability,
        "pres_total_error": pres_total_error,
        "temp": temp,
        "temp_sensor_error": temp_sensor_error,
        "temp_var": temp_variability,
        "temp_total_error": temp_total_error,
        "humidity": humidity,
        "humidity_sensor_error": humidity_sensor_error,
        "humidity_var": humidity_variability,
        "humidity_total_error": humidity_total_error,
        "co2": co2,
        "co2_sensor_error": co2_sensor_error,
        "co2_var": co2_variability,
        "co2_total_error": co2_total_error,
        "time": time,
    }
    wn_min, trans_min = np.loadtxt(
        folder + f"{version}/{file_number}_min.txt",
        unpack=True
    )
    wn_max, trans_max = np.loadtxt(
        folder + f"{version}/{file_number}_max.txt",
        unpack=True
    )
    return wn_min, trans_min, wn_max, trans_max, data


def average_ints_in_folder(FOLDER, len_int=0, return_n=True, centre_place=False):
    """Load all interferograms from a foder created by the Opus software 
    and return the averaged interferogram and the start and end times of the
    interferogram

    Args:
        FOLDER (string): location of folder
        len_int (int, optional): length of the interferogram, if 0 then the 
        length of the first interferogram is taken. Defaults to 0.
        return_n (bool, optional): Return the number of interferograms
         in the folder. Defaults to True.
        centre_place (bool, optional): Return the position of the centre burst
         these should be (pretty much) the same while averaging. Defaults to False.

    Returns:
        array: averaged interferogram
        tuple: start and end times for the average interferogram
        int: if return_n=True: Number of interferograms averaged
        list: if centre_place=True: List of centre burst locations
    """
    ints_names = glob(FOLDER + "/*.0")
    ints_names.sort()
    centre_places = []
    for i, name in enumerate(ints_names):
        data = np.fromfile(name, np.float32)
        # print("Int: ", name)
        centre_point = np.argmax(data[10000:-10000])
        centre_places.append(centre_point)
        if i == 0:
            if len_int==0:
                ints = np.empty((len(ints_names), len(data)))
            else:
                ints = np.empty((len(ints_names), len_int))
        if len_int==0:
            ints[i, :] = data
        else:
            ints[i, :] = data[0:len_int]
    times_name = glob(FOLDER + "/*ResultSeries.txt")[0]
    time_strings = np.loadtxt(
        times_name, dtype="str", delimiter="\t", skiprows=2, usecols=[1], unpack=True,
    )
    times = []
    for time in time_strings:
        times.append(string_to_seconds_bruker(time))
    if not all_equal(centre_places):
        print("Warning, centre burst not in same position when averaging")
        print(FOLDER)
        print(centre_places)
    average_int = np.average(ints, axis=0)
    start_end = (min(times), max(times))
    n = len(ints_names)
    if return_n and centre_place:
        return average_int, start_end, n, centre_places
    elif return_n:
        return average_int, start_end, n
    elif centre_place:
        return average_int, start_end, centre_places
    else:
        return average_int, start_end
    

def calibrate_fixed_response_function(
    int_scene,
    int_HBB,
    temp_HBB,
    wn_resp,
    resp,
    resolution=0.5,
    fre_interval=0.01,
    low_res_trunk=16384,
    NESR_number=20,
):
    """Calibrate scene view using interferogram method

    Args:
        int_scene (np.array): interferogram of scene view
        int_HBB (np.array): interferogram of HBB
        int_CBB (np.array): interferogram of CBB
        temp_HBB (float): temperature of HBB (degC)
        temp_CBB (float): temperature of CBB (degC)
        resolution (float, optional): Resolution of output spectrum.
            Defaults to 0.5.
        fre_interval (float, optional): Frequency grid for output
            spectrum. Defaults to 0.01.
        low_res_trunk (int, optional): Number of points used to calculate
            phase angle. Defaults to 16384.
        NESR_number (int, optional): Number of points used in rolling
            window to calculate NESR. Defaults to 20.

    Returns:
        np.array: wavenumber scale (cm-1)
        np.array: radiance (W/m^2/sr/cm-1)
        np.array: NESR (W/m^2/sr/cm-1)
    """
    # Calculate spectrum of scene minus HBB
    spectrum_scene, _ = finesse_fft(
        int_scene - int_HBB, resolution, fre_interval, low_res_trunk
    )

    # Check wn scales are the same
    print(wn_resp)
    print(spectrum_scene[0, 1:])
    if not np.all(wn_resp == spectrum_scene[0, 1:]):
        print("Wn scales different something is wrong")
        return None

    L_HBB = planck(wn_resp, temp_HBB)

    rad_scene = (spectrum_scene[1, 1:] / resp) + L_HBB

    # Calculate NESR from imaginary part of corrected spectrum
    rad_NESR = spectrum_scene[2, 1:] / resp
    rad_NESR = pd.DataFrame(rad_NESR, columns=["rad"])
    NESR = rad_NESR.rad.rolling(NESR_number).std()

    return wn_resp, rad_scene, NESR


def create_single_wn_wl_plot(
    figure,
    wn,
    data,
    title='',
    xlab=r'Wavenumber (cm$^{-1}$)',
    xlab2=r'Wavelength ($\mu$m)',
    ylab='',
    xlim=None,
    ylim=None,
    line_width=1,
    alpha=1,
    color='k',
    show_grid=True,
    ):
    """Plot a graph with a lower x-axis in cm-1 and an upper x-axis
    in micrometers

    Args:
        figure (fig): The figure to add axes to
        wn (array/list): The wavenumbers to be plotted (cm-1)
        data (array/list): The data as a function of wavenumber
        title (str, optional): Title of the plot. Defaults to ''.
        xlab (str, optional): Lower x label of plot. Defaults to r'Wavenumber (cm$^{-1}$)'.
        xlab2 (str, optional): Upper x label of plot. Defaults to r'Wavelength ($\mu)'.
        ylab (str, optional): Y label of plot. Defaults to ''.
        xlim (tuple (a, b), optional): x lims for plot. If None this is 
        set automatically. Defaults to None.
        ylim (tuple(a, b), optional): y lims for plot. If None this is
        set automatically. Defaults to None.
        line_width (int, optional): Linewidth for plot. Defaults to 1.
        alpha (int, optional): Alpha for plot. Defaults to 1.
        color (str, optional): Color for plot line. Defaults to 'k'.
        show_grid (bool, optional): Show grid for plot. Defaults to True.
    
    Returns:
        fig: Figure
    """
    ax1 = figure.add_subplot(1,1,1) # here is where you add the subplot to f
    ax2 = ax1.secondary_xaxis("top", functions=(wn_to_wl, wl_to_wn))
    plt.plot(wn, data, linewidth=line_width,
               alpha=alpha, color=color)
    ax1.set_xlabel(xlab)
    ax2.set_xlabel(xlab2)
    ax1.set_ylabel(ylab)
    if xlim is not None:
        ax1.set_xlim(xlim)
    if ylim is not None:
        ax1.set_ylim(ylim)
    plt.grid(show_grid)
    plt.title(title)
    return figure




def average_ints_in_folder_return_individuals(FOLDER, len_int=0, return_n=True, centre_place=False):
    """Load all interferograms from a foder created by the Opus software 
    and return the averaged interferogram and the start and end times of the
    interferogram

    Args:
        FOLDER (string): location of folder
        len_int (int, optional): length of the interferogram, if 0 then the 
        length of the first interferogram is taken. Defaults to 0.
        return_n (bool, optional): Return the number of interferograms
         in the folder. Defaults to True.
        centre_place (bool, optional): Return the position of the centre burst
         these should be (pretty much) the same while averaging. Defaults to False.

    Returns:
        array: averaged interferogram
        tuple: start and end times for the average interferogram
        int: if return_n=True: Number of interferograms averaged
        list: if centre_place=True: List of centre burst locations
    """
    ints_names = glob(FOLDER + "/*.0")
    ints_names.sort()
    centre_places = []
    for i, name in enumerate(ints_names):
        data = np.fromfile(name, np.float32)
        # print("Int: ", name)
        centre_point = np.argmax(data[10000:-10000])
        centre_places.append(centre_point)
        if i == 0:
            if len_int == 0:
                ints = np.empty((len(ints_names), len(data)))
            else:
                ints = np.empty((len(ints_names), len_int))
        if len_int == 0:
            ints[i, :] = data
        else:
            ints[i, :] = data[0:len_int]
    times_name = glob(FOLDER + "/*ResultSeries.txt")[0]
    time_strings = np.loadtxt(
        times_name, dtype="str", delimiter="\t", skiprows=2, usecols=[1], unpack=True,
    )
    times = []
    for time in time_strings:
        times.append(string_to_seconds_bruker(time))
    if not all_equal(centre_places):
        print("Warning, centre burst not in same position when averaging")
        print(FOLDER)
        print(centre_places)
    # average_int = np.average(ints, axis=0) # this line removal is the only difference
    # start_end = (min(times), max(times))
    n = len(ints_names)
    print(times)
    if return_n and centre_place:
        return ints, times, n, centre_places
    elif return_n:
        return ints, times, n
    elif centre_place:
        return ints, times, centre_places
    else:
        return ints, times


"""
Below is code written by Chrisopher O'Sullivan
More helper functions for spectrum calibration
"""


def load_single_int(filename):
    """Load single interferogram produced using
        2_prepare_interferogram.py; adapted from load_average_int

        Args:
            filename (string): Location of interferogram file

        Returns:
            array: interferogram
            array: start time of interfergram (appears twice in the list for consistency with other methods)
            float: mirror angle for interferogram
        """
    interferogram = np.loadtxt(filename)
    with open(filename, "r") as f:
        for i, line in enumerate(f):
            if i == 2:
                times_raw = line
            if i == 3:
                angle_raw = line
            if i > 3:
                break
    times_split = times_raw.split(" ")[1:]
    time = np.array((times_split[0], times_split[0]), dtype=float)
    angle = float(angle_raw[2:-1])
    return interferogram, time, angle


def calculate_nesr_from_bb(bb_ints):
    """DEPRECATED but kept here as a record.

    Find the residual between one interferogram and the average of the other interferograms in a scan
    cycle in order to calculate the NESR. Can be applied to hot or cold blackbody.

    Args:
        bb_ints (np.array): list containing all the interferogram radiances of a blackbody from a single scan cycle

    Returns:
        np.array: NESR for this cycle
    """
    # separate first interferogram from others, and take average of all others
    separated_rad = bb_ints[0]
    rads_to_average = bb_ints[1:]
    average_rad = np.zeros(len(rads_to_average[0]))  # initialise list for averages
    for rads in rads_to_average:
        for j, rad in enumerate(rads):
            average_rad[j] += rad / len(rads_to_average)  # contribute to the average list
    # find difference of radiance at each wavenumber between first interferogram and average interferogram
    nesr = []
    for i in range(len(separated_rad)):
        nesr.append(average_rad[i] - separated_rad[i])
    return np.array(nesr)


def calculate_nesr(wns, rads):
    """Calculate the NESR.

    Args:
        wns (np.array): List of list of wavenumbers for all scans
        rads (np.array): List of list of radiances for all scans at the wavenumber of the same index in wn

    Returns:
        float: NESR
    """
    # get difference between each radiance
    rad_differences = []
    for i in range(len(rads) - 1):
        current_rad = rads[i]
        next_rad = rads[i + 1]
        rad_difference = []
        for j in range(len(current_rad)):
            rad_difference.append(next_rad[j] - current_rad[j])
        rad_differences.append(rad_difference)

    # get the RMS of the differences in rolling 5 cm^-1 bands
    # get indices of the rolling 5 cm^-1 bands
    first_wavenumber = 400
    last_wavenumber = 1605
    indices = []
    for i, wn in enumerate(wns[0]):  # all the wavenumbers for every scan should be the same
        if first_wavenumber < wn < last_wavenumber:
            indices.append([i, i + 100])        # wavenumber increases by 5 cm^-1 after 100 steps

    # get RMS for the radiances inside the bands
    nesr_values = []
    for i, index in enumerate(indices):
        start_index = index[0]
        end_index = index[1]
        # go through all the radiance difference lists, get RMS for each list, then take square root of mean RMS
        rms_for_each_scan = []
        for j, rad_difference_list in enumerate(rad_differences):
            # get RMS of radiance differences in this wavenumber range for this scan
            relevant_square_rad_differences = []
            for rad_difference in rad_difference_list[start_index:end_index]:
                relevant_square_rad_differences.append(rad_difference ** 2)     # square the difference to get RMS later
            # take mean and square root to get RMS
            rms_for_each_scan.append(np.sqrt(np.mean(relevant_square_rad_differences)))
        # take mean of RMS for each scan, then take square root to get NESR
        nesr = np.sqrt(np.mean(rms_for_each_scan))
        # return with the start index (which is the index for which this NESR is valid)
        nesr_values.append([start_index, nesr])

    # create a list with NESR values between the first and last wavenumber. Outside of those bounds, return nan
    nesr = []
    for i in range(len(wns[0])):
        if indices[0][0] <= i <= indices[-1][0]:
            nesr.append(nesr_values[i-indices[0][0]][1])
        else:
            nesr.append(np.nan)

    return nesr
